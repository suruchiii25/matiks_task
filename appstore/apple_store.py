"""
Apple App Store review collector for Matiks app.

Assignment: "Collect user reviews from Google Play Store and Apple App Store
including ratings, review text, dates, and version details when available."

Uses app-store-scraper for live reviews. Falls back to demo data if fetch fails.
Note: Apple's review API often returns empty/non-JSON (block or changed API);
demo data keeps the pipeline running. Swap in official App Store Connect API
if you have developer access.
"""
import logging
import os
import math
from typing import Optional

import pandas as pd

APP_NAME = os.getenv("APPLE_APP_NAME", "Matiks")
# Matiks Apple App Store ID (https://apps.apple.com/us/app/matiks-math-and-mind-games/id6738620563)
APP_ID = int(os.getenv("APPLE_APP_ID", "6738620563"))
REVIEW_COUNT = int(os.getenv("APPLE_REVIEW_COUNT", "100"))

# IMPORTANT (assumption based on how Apple works):
# Apple reviews are storefront-specific (there isn't one global feed).
# To match the assignment without guessing a single country, we default to
# collecting across common storefronts and de-duping.
AUTO_STOREFRONTS = [
    "us",
    "in",
    "gb",
    "ca",
    "au",
    "sg",
    "ae",
    "de",
    "fr",
]

_countries_env = os.getenv("APPLE_COUNTRIES", "auto").strip().lower()
if _countries_env in ("", "auto"):
    COUNTRIES_TO_TRY = AUTO_STOREFRONTS
else:
    # Comma-separated storefronts to try, e.g. "us,in,gb"
    COUNTRIES_TO_TRY = [c.strip().lower() for c in _countries_env.split(",") if c.strip()]

REQUIRED_COLUMNS = ["rating", "review_text", "date", "version"]


def _safe_get(d: dict, path: list[str], default=""):
    cur: object = d
    for key in path:
        if not isinstance(cur, dict) or key not in cur:
            return default
        cur = cur[key]
    return cur if cur is not None else default


def fetch_apple_store_reviews_rss(
    *,
    country: str,
    count: int,
    app_id: int,
    page_size: int = 50,
) -> Optional[pd.DataFrame]:
    """
    Fetch reviews via Apple's public RSS JSON feed.

    This is often more reliable than third-party scrapers.
    Includes `im:version` (app version) when present.
    """
    try:
        import requests
    except Exception as e:
        raise ImportError(f"requests is required for RSS fetch: {e}") from e

    headers = {"User-Agent": "Mozilla/5.0 (compatible; MatiksMonitor/1.0)"}
    rows: list[dict] = []
    seen_urls: set[str] = set()

    pages = max(1, int(math.ceil(count / float(page_size))))
    for page in range(1, pages + 1):
        url = f"https://itunes.apple.com/{country}/rss/customerreviews/page={page}/id={app_id}/sortBy=mostRecent/json"
        resp = requests.get(url, headers=headers, timeout=25)
        if resp.status_code != 200:
            continue

        try:
            payload = resp.json()
        except Exception:
            # Sometimes Apple returns HTML or empty content unexpectedly.
            continue

        entries = _safe_get(payload, ["feed", "entry"], default=[])
        if not isinstance(entries, list) or not entries:
            continue

        # Feed includes an app metadata entry; reviews typically have `im:rating`.
        review_entries = [e for e in entries if isinstance(e, dict) and "im:rating" in e]
        if not review_entries:
            continue

        for e in review_entries:
            review_id = str(_safe_get(e, ["id", "label"], default="")).strip()
            url_from_feed = str(_safe_get(e, ["link", "attributes", "href"], default="")).strip()
            url = url_from_feed or f"https://itunes.apple.com/{country}/rss/customerreviews/id={app_id}/sortBy=mostRecent/json"

            if review_id and review_id in seen_urls:
                continue

            rating_raw = _safe_get(e, ["im:rating", "label"], default="")
            try:
                rating = int(str(rating_raw).strip())
            except Exception:
                rating = None

            date_val = str(_safe_get(e, ["updated", "label"], default="")).strip()
            version = str(_safe_get(e, ["im:version", "label"], default="")).strip()
            author = str(_safe_get(e, ["author", "name", "label"], default="")).strip()
            title = str(_safe_get(e, ["title", "label"], default="")).strip()
            content = str(_safe_get(e, ["content", "label"], default="")).strip()

            # Prefer full review text; fall back to title if content missing.
            review_text = content or title or ""

            rows.append(
                {
                    "rating": rating,
                    "review_text": review_text,
                    "date": date_val,
                    "version": version,
                    "author": author,
                    "review_id": review_id,
                    "url": url,
                    "country": country,
                }
            )
            if review_id:
                seen_urls.add(review_id)

            if len(rows) >= count:
                break

        if len(rows) >= count:
            break

    if not rows:
        return None
    df = pd.DataFrame(rows)
    # Ensure required columns exist (assignment requirement)
    for col in REQUIRED_COLUMNS:
        if col not in df.columns:
            df[col] = ""
    return df


def fetch_apple_store_reviews(app_name=None, country=None, count=None, app_id=None, *, all_countries: bool = True):
    """Fetch live reviews: ratings, review text, dates (per assignment). Version when available from scraper."""
    app_name = app_name or APP_NAME
    count = count if count is not None else REVIEW_COUNT
    app_id = app_id if app_id is not None else APP_ID
    countries = [country] if country else COUNTRIES_TO_TRY

    # 1) Try Apple's RSS JSON feed first (usually the most reliable)
    rss_dfs: list[pd.DataFrame] = []
    for c in countries:
        try:
            df = fetch_apple_store_reviews_rss(country=c, count=count, app_id=app_id)
            if df is not None and not df.empty:
                print(f"Fetched {len(df)} reviews from Apple RSS feed (storefront={c})")
                rss_dfs.append(df)
                if not all_countries:
                    break
        except Exception:
            continue

    if rss_dfs:
        out = pd.concat(rss_dfs, ignore_index=True)
        # De-dupe across countries by review_id (most reliable), else by content fingerprint.
        if "review_id" in out.columns:
            out = out.drop_duplicates(subset=["review_id"])
        else:
            out = out.drop_duplicates(subset=["author", "date", "review_text", "rating"])
        # Ensure required columns exist (assignment requirement)
        for col in REQUIRED_COLUMNS:
            if col not in out.columns:
                out[col] = ""
        return out

    # 2) Fallback: app-store-scraper (kept for completeness)
    try:
        from app_store_scraper import AppStore
    except ImportError:
        return None

    # Reduce scraper log noise when Apple returns empty/non-JSON
    logging.getLogger("Base").setLevel(logging.WARNING)

    app = None
    for c in countries:
        try:
            _app = AppStore(country=c, app_name=app_name, app_id=app_id)
            _app.review(how_many=count)
            if _app.reviews:
                app = _app
                print(f"Fetched {len(_app.reviews)} reviews via app-store-scraper (country={c})")
                break
        except Exception:
            continue
    if not app or not app.reviews:
        return None

    rows = []
    for r in app.reviews:
        date_val = r.get("date")
        if hasattr(date_val, "isoformat"):
            date_val = date_val.isoformat()
        rows.append(
            {
                "rating": r.get("rating"),  # assignment: ratings
                "review_text": (r.get("review") or r.get("title") or "").strip() or "",  # assignment: review text
                "date": date_val,  # assignment: dates
                "version": "",  # version usually not present in this scraper output
                "author": r.get("userName") or "",
                "url": "",
                "country": "",
            }
        )
    df = pd.DataFrame(rows)
    for col in REQUIRED_COLUMNS:
        if col not in df.columns:
            df[col] = ""
    return df


def fetch_apple_store_reviews_demo():
    """Demo data when live fetch fails (rating, review_text, date, version)."""
    data = [
        {"rating": 5, "review_text": "Best math duel app. Addictive and fun.", "date": "2026-01-28T10:00:00", "version": "2.1.0", "author": "iOS User"},
        {"rating": 5, "review_text": "Improved my mental math a lot. Recommend.", "date": "2026-01-25T14:30:00", "version": "2.0.9", "author": "MathFan"},
        {"rating": 4, "review_text": "Great app, sometimes crashes on older iPhone.", "date": "2026-01-22T09:15:00", "version": "", "author": "TechUser"},
    ]
    return pd.DataFrame(data)


if __name__ == "__main__":
    try:
        print("Fetching Apple App Store reviews for Matiks...")
        df = fetch_apple_store_reviews(count=REVIEW_COUNT)
        if df is None or df.empty:
            raise ValueError("No reviews returned")
    except Exception as e:
        print(f"Live fetch failed: {e}")
        print("Apple review API returned no data (common: block/empty response). Using demo data.")
        df = fetch_apple_store_reviews_demo()

    df["platform"] = "Apple App Store"
    # Ensure required columns exist in output (assignment requirement)
    for col in REQUIRED_COLUMNS:
        if col not in df.columns:
            df[col] = ""
    print(f"Fetched {len(df)} reviews (rating, review_text, date per assignment).")
    print(df.head())
    os.makedirs("output", exist_ok=True)
    df.to_csv("output/apple_store_reviews.csv", index=False)
    with open("output/apple_store_reviews.html", "w", encoding="utf-8") as f:
        f.write("<meta charset='utf-8'><h1>Apple App Store reviews â€“ Matiks</h1>")
        f.write(df.to_html(index=False, classes="table", border=1))
    print("Saved to output/apple_store_reviews.csv and .html")
